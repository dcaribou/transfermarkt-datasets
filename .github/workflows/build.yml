name: build

on:
  push:
    branches: [master]
  pull_request:
    branches: [master]

jobs:
  build:
    if: github.event.pull_request.head.repo.fork == false
    concurrency: build_queue
    runs-on: ubuntu-latest
    container:
      image: dcaribou/transfermarkt-datasets:linux-amd64-master
    defaults:
      run:
        shell: bash -l {0}

    steps:
      - name: checkout
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.PA_GITHUB_TOKEN }}

      - name: Run tests and build
        run: |
          set -e
          just --set dbt_target prod dvc_pull test prepare_local
          dvc commit -f
          git config --global --add safe.directory '*'

      - name: Validate provenance columns
        run: |
          set -e
          python -c "
          import duckdb
          conn = duckdb.connect('dbt/duck.db', read_only=True)
          errors = []
          for model in ['competitions', 'clubs', 'games']:
              cols = [r[0] for r in conn.sql(f\"SELECT column_name FROM information_schema.columns WHERE table_schema='prod' AND table_name='{model}'\").fetchall()]
              for required in ['source_system', 'source_record_id', 'ingested_at']:
                  if required not in cols:
                      errors.append(f'{model} missing provenance column: {required}')
              # Check source_system is populated
              nulls = conn.sql(f\"SELECT count(*) FROM prod.{model} WHERE source_system IS NULL\").fetchone()[0]
              if nulls > 0:
                  errors.append(f'{model} has {nulls} rows with NULL source_system')
          conn.close()
          if errors:
              for e in errors:
                  print(f'ERROR: {e}')
              exit(1)
          else:
              print('All provenance columns validated successfully')
          "

      - name: Run profiling drift checks
        run: |
          python scripts/profiling/profile_models.py --db dbt/duck.db --schema prod

      - name: Get branch name
        id: branch-name
        uses: tj-actions/branch-names@v7

      - uses: EndBug/add-and-commit@v9
        if: ${{ !contains(github.event.head_commit.message, 'updated prepared dataset files') }}
        with:
          add: 'data/prep.dvc'
          message: 'ðŸ¤– updated prepared dataset files'
          default_author: github_actions
          new_branch: ${{ steps.branch-name.outputs.current_branch }}
          pull: '--no-rebase'

      - name: Push to dvc
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
        run: |
          dvc push --remote r2

  build-image:
    runs-on: ubuntu-latest
    needs: build
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - name: checkout
        uses: actions/checkout@v3
      - name: Get changed files
        id: changed-files
        uses: tj-actions/changed-files@v40
        with:
          files: |
            data/**/*.dvc
      - uses: extractions/setup-just@v2

      - name: image build
        env:
          DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
        # only run the build if the changed files are not only dvc files
        if: ${{ steps.changed-files.outputs.only_changed == 'false' }}
        run: |
          # set image tag accordingly

          REF=$(echo $GITHUB_REF | awk 'BEGIN { FS = "/" } ; { print $3 }')
          if [ $REF = master ];
          then
            TAG=master
          else
            TAG=dev
          fi

          # build and push
          just --set tag "$TAG" --set platform "linux/amd64" docker_build docker_push_dockerhub
