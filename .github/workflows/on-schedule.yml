name: Tansfermarkt Datasets Data Pipeline

on:
  schedule:
    - cron: '0 4 * * TUE'
  workflow_dispatch:
    inputs:
      message:
        required: false
        default: 'ðŸ¤– updated dataset files'
        description: Commit message for the 'add-and-commit' step

jobs:
  data-pipeline:

    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}

    steps:
      - name: checkout
        uses: actions/checkout@v2

      - uses: conda-incubator/setup-miniconda@v2
        with:
          environment-file: environment.yml
          activate-environment: transfermarkt-datasets
          
      - name: run acquire
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: eu-west-1
        run: |
          # trigger prep job in aws batch

          DAY=$(date +"%Y-%m-%d")
          JOB_DEFINITION_NAME=transfermarkt-datasets-batch-job-definition-master

          make \
            acquire_cloud \
              JOB_DEFINITION_NAME=$JOB_DEFINITION_NAME \
              JOB_NAME=on-schedule-$DAY \
              BRANCH=master
