name: Tansfermarkt Datasets Data Pipeline

on:
  schedule:
    - cron: '0 4 * * TUE'
  workflow_dispatch:
    inputs:
      message:
        required: false
        default: ':wrench: Github Actions: Manually updated dataset files'
        description: Commit message for the 'add-and-commit' step

jobs:
  data-pipeline:

    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}

    steps:
    - run: |
        echo "${{ github.event.head_commit.message }}"
    - uses: actions/checkout@v2
      # a different (personal access) github token need to be setup here so that a 'add-and-commit' step below triggers the 'on-push' workflow
      # checkout https://github.community/t/push-from-action-does-not-trigger-subsequent-action/16854
      with:
        token: ${{ secrets.PA_GITHUB_TOKEN}}
    - uses: conda-incubator/setup-miniconda@v2
      with:
        environment-file: environment.yml
        activate-environment: transfermarkt-datasets
    - name: Acquire
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_EC2_METADATA_DISABLED: true # https://github.com/aws/aws-cli/issues/5262
      run: |
        git checkout ga-updates
        bash run_pipeline.sh
    - uses: EndBug/add-and-commit@v7
      with:
        add: 'data/*.dvc'
        message: "${{ github.event.inputs.name || ':wrench: Github Actions: Updated dataset files'}}"
        default_author: github_actions
    - name: sync cache
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: |
        python 3_sync.py --cache-only --season 2021
