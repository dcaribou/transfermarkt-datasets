name: Tansfermarkt Datasets Data Pipeline

on:
  schedule:
    - cron: '0 4 * * TUE'
  workflow_dispatch:
    inputs:
      message:
        required: false
        default: ':wrench: Github Actions: Manually updated dataset files'
        description: Commit message for the 'add-and-commit' step

jobs:
  data-pipeline:

    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}

    steps:
      - name: run prep
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: eu-west-1
        run: |
          # trigger prep job in aws batch

          DAY=$(date +"%Y-%m-%d")
          JOB_DEFINITION_NAME=transfermarkt-datasets-batch-job-definition-dev # TODO: switch to master
          EXEC_COMMAND=1_acquire.py,--asset,games,--season,2021

          # TODO: switch BRANCH to master, COMMAND to all
          make \
            run_batch \
              JOB_DEFINITION_NAME=$JOB_DEFINITION_NAME \
              JOB_NAME=on-schedule-$DAY \
              EXEC_COMMAND=$EXEC_COMMAND \ 
              BRANCH=fargate-tasks # TODO: switch to master
