name: Tansfermarkt Datasets Data Pipeline

on:
  schedule:
    - cron: '0 4 * * TUE'
  workflow_dispatch:
    inputs:
      message:
        required: false
        default: ':wrench: Github Actions: Manually updated dataset files'
        description: Commit message for the 'add-and-commit' step

jobs:
  data-pipeline:

    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}

    steps:
    - name: Acquire
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: |
        aws batch submit-job \
          --job-name on-schedule-$(date +"%Y-%m-%d") \
          --job-queue transfermarkt-datasets-batch-compute-job-queue \
          --job-definition transfermarkt-datasets-batch-job-definition \
          --container-overrides \
            command=./acquire_on_batch.sh \
            image=dcaribou/transfermarkt-datasets:master \
            vcpus=2 \
            memory=1024
